{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTeKYOE-Gft",
        "outputId": "f6a02ea2-075a-4597-c6b9-fa4857a6a42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "2. Preparing Data Generators...\n",
            "Found 3692 images belonging to 2 classes.\n",
            "3. Building and Training Model...\n",
            "   (Training completed successfully. Proceeding to conversion.)\n",
            "\n",
            "4. Converting to TFLite (Quantization)...\n",
            "Saved artifact at '/tmp/tmpjnhl62nb'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='keras_tensor_8')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139016640714064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139016640714832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139016640712912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139016640713296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139016640715984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139016640715216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139016640716368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139016640716176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3692 images belonging to 2 classes.\n",
            "   Generating 100 representative data samples for quantization...\n",
            "✅ TFLite model saved successfully to: /content/drive/MyDrive/EdgeImpulse_VWW/dataset_person_vww/person_detector_quantized.tflite\n",
            "   Model size: 979.84 KB\n",
            "\n",
            "5. Converting to C Array Header...\n",
            "✅ C Header file saved successfully to: /content/drive/MyDrive/EdgeImpulse_VWW/dataset_person_vww/person_model.h\n",
            "\n",
            "--- Pipeline Confirmed! Files are ready for your ESP32S3 project. ---\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import drive\n",
        "import math\n",
        "\n",
        "# --- 1. CONFIGURATION: VERIFY VALUES BELOW ---\n",
        "# The path to your VWW dataset parent folder in Google Drive\n",
        "BASE_DIR = '/content/drive/MyDrive/EdgeImpulse_VWW/dataset_person_vww'\n",
        "IMG_SIZE = (96, 96)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "# -----------------------------------------------\n",
        "\n",
        "# --- 2. MOUNT GOOGLE DRIVE ---\n",
        "print(\"1. Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# --- 3. DATA PREPARATION ---\n",
        "print(\"2. Preparing Data Generators...\")\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    BASE_DIR,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# --- 4. MODEL DEFINITION AND TRAINING ---\n",
        "print(\"3. Building and Training Model...\")\n",
        "\n",
        "# Define the model (must match the one you trained)\n",
        "model = Sequential([\n",
        "    Conv2D(16, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Re-run training (verbose=0 suppresses the epoch output)\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=0\n",
        ")\n",
        "print(\"   (Training completed successfully. Proceeding to conversion.)\")\n",
        "\n",
        "# --- 5. TFLITE CONVERSION (FIXED) ---\n",
        "print(\"\\n4. Converting to TFLite (Quantization)...\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Define a representative dataset generator (FIXED to use a simple counter)\n",
        "def representative_data_gen(steps_to_yield=100):\n",
        "    # Create a separate generator for representative data (batch_size=1)\n",
        "    rep_data_generator = datagen.flow_from_directory(\n",
        "        BASE_DIR,\n",
        "        target_size=IMG_SIZE,\n",
        "        batch_size=1,\n",
        "        class_mode='binary',\n",
        "        subset='training',\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    print(f\"   Generating {steps_to_yield} representative data samples for quantization...\")\n",
        "    for i, (input_value, _) in enumerate(rep_data_generator):\n",
        "        yield [input_value.astype(np.float32)]\n",
        "        if i >= steps_to_yield - 1:\n",
        "            break\n",
        "\n",
        "# Configure and perform the conversion\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "tflite_model_quant = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "tflite_model_path = os.path.join(BASE_DIR, 'person_detector_quantized.tflite')\n",
        "with open(tflite_model_path, 'wb') as f:\n",
        "    f.write(tflite_model_quant)\n",
        "\n",
        "print(f\"✅ TFLite model saved successfully to: {tflite_model_path}\")\n",
        "print(f\"   Model size: {os.path.getsize(tflite_model_path) / 1024:.2f} KB\")\n",
        "\n",
        "\n",
        "# --- 6. C ARRAY CONVERSION ---\n",
        "print(\"\\n5. Converting to C Array Header...\")\n",
        "\n",
        "def convert_to_c_array(tflite_bytes, variable_name=\"model\"):\n",
        "    # Convert bytes to a C-style hex string array\n",
        "    hex_array = ', '.join([f'0x{b:02x}' for b in tflite_bytes])\n",
        "\n",
        "    # Create the C header file content\n",
        "    c_code = f\"\"\"\n",
        "// Auto-generated file for TFLite Micro deployment.\n",
        "// Model name: {variable_name}\n",
        "// Model size: {len(tflite_bytes)} bytes\n",
        "const unsigned char {variable_name}[] __attribute__((aligned(16))) = {{\n",
        "  {hex_array}\n",
        "}};\n",
        "const int {variable_name}_len = {len(tflite_bytes)};\n",
        "\"\"\"\n",
        "    return c_code\n",
        "\n",
        "# Get the C array code\n",
        "c_array_code = convert_to_c_array(tflite_model_quant, variable_name=\"person_model\")\n",
        "\n",
        "# Save the C array to a header file\n",
        "header_file_path = os.path.join(BASE_DIR, 'person_model.h')\n",
        "with open(header_file_path, 'w') as f:\n",
        "    f.write(c_array_code)\n",
        "\n",
        "print(f\"✅ C Header file saved successfully to: {header_file_path}\")\n",
        "\n",
        "print(\"\\n--- Pipeline Confirmed! Files are ready for your ESP32S3 project. ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "539f9b28"
      },
      "source": [
        "### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "e9ffb8db",
        "outputId": "0b6c8424-db06-470f-8daf-4a47be0fb18d"
      },
      "source": [
        "print('Model Summary:')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m94\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m47\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15488\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m991,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">47</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15488</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">991,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,989,349\u001b[0m (11.40 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,989,349</span> (11.40 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m996,449\u001b[0m (3.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">996,449</span> (3.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,992,900\u001b[0m (7.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,992,900</span> (7.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2e8727a"
      },
      "source": [
        "### Model Training Performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "131ec45e",
        "outputId": "ee9a4a16-141a-46a9-d040-289d048b4aaa"
      },
      "source": [
        "print('Evaluating model on training data...')\n",
        "loss, accuracy = model.evaluate(train_generator, verbose=0)\n",
        "print(f\"Training Loss: {loss:.4f}\")\n",
        "print(f\"Training Accuracy: {accuracy:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model on training data...\n",
            "Training Loss: 0.1619\n",
            "Training Accuracy: 0.9445\n"
          ]
        }
      ]
    }
  ]
}